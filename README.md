# Language Models Workshop

This repository contains Jupyter notebooks, Python and R scripts for working with language models.

## Open in Google Colab

Click the link below to open the notebook in Google Colab:

- [Groq API Basic (Python)](https://colab.research.google.com/github/tpetric7/language_models_workshop/blob/main/Groq_API_basic_Google_Colab.ipynb)
- [Groq API Summarize (Python)](https://colab.research.google.com/github/tpetric7/language_models_workshop/blob/main/Groq_API_summarize_Google_Colab.ipynb)
- [Sentiment Trump Inauguration 2025 (Python)](https://colab.research.google.com/github/tpetric7/language_models_workshop/blob/main/Sentiment_in_colors_Trump_Inaugural_Speech.ipynb)
- [Sentiment Cyberattack (Python)](https://colab.research.google.com/github/tpetric7/language_models_workshop/blob/main/Sentiment_in_colors_Cyberattack.ipynb)
- [Sentiment Cyberattack (R)](https://colab.research.google.com/github/tpetric7/language_models_workshop/blob/main/R_Py_sentiment_Colab.ipynb)
- [Semantic Search txtai (Python)](https://colab.research.google.com/github/tpetric7/language_models_workshop/blob/main/Semantic_Search_txtai.ipynb)
- [Topic Analysis BERTopicr (R)](https://colab.research.google.com/github/tpetric7/language_models_workshop/blob/main/R_Py_bertopicr_Colab.ipynb)
- [Translate Text (Python, Google Translate)](https://colab.research.google.com/github/tpetric7/language_models_workshop/blob/main/translate_doc_google.ipynb)
- [Whisper Transcribe Audio file (Python)](https://colab.research.google.com/github/tpetric7/language_models_workshop/blob/main/Whisper_transcribe.ipynb).

## Open on local machine

- Download the raw file from the GitHub repository, 
- download and install Ollama (if you intend to use a local model), 
- download a language model (run by Ollama), 
- download and install Python or R (see Instructions below), 
- activate a Python virtual environment (see Instructions below), 
- and run the Python or R file in a terminal (see Instructions below).

Click the link below to open and download the Python /- or R -- file and run it locally:

- [Streamlit Chatbot (Python, local Ollama model)](https://github.com/tpetric7/language_models_workshop/blob/main/streamlit_chatbot2.py) - run it with 'streamlit run streamlit_chatbot2.py'.
- [Shiny Chatbot (R, local Ollama model)](https://github.com/tpetric7/language_models_workshop/blob/main/ollama_chatbot.R) - run it with 'shiny::runApp("ollama_chatbot.R")'.
- [Shiny Chatbot (R, Groq model)](https://github.com/tpetric7/language_models_workshop/blob/main/groq_chat_app.R) - run it with 'shiny::runApp("groq_chat_app.R")'.
- [Topics in the newspaper Dnevnik (R, Groq model, BERTopicr)](https://github.com/tpetric7/language_models_workshop/blob/main/topics_in_dnevnik.qmd) - run the Quarto markdown file with RStudio (cf. to https://github.com/tpetric7/bertopic-r).
- [Topics in the newspaper Dnevnik (R, Groq model, BERTopicr)](https://github.com/tpetric7/language_models_workshop/blob/main/topics_in_dnevnik.R) - run the R script with RStudio (cf. to https://github.com/tpetric7/bertopic-r).
- [Streamlit Chat with PDF (Python, local Ollama model)](https://github.com/tpetric7/language_models_workshop/blob/main/chat_with_pdf.py) - run it with 'streamlit run chat_with_pdf.py'.
- [Chainlit Chat with PDF (Python, Ollama, local Slovenian model)](https://github.com/tpetric7/language_models_workshop/blob/main/chat_with_pdf_sl.py) - run it with 'chainlit run chat_with_pdf_sl.py'.

## Instructions for installing Python, Chainlit, Streamlit, R and Shiny on your local machine

- [Python & Streamlit installation guide](https://github.com/tpetric7/language_models_workshop/blob/main/Streamlit_app_how_to_prepare.pdf)
- [Python & Chainlit installation guide](https://github.com/tpetric7/language_models_workshop/blob/main/Chainlit_app_how_to_prepare.pdf)
- [R, RStudio & Shiny installation guide](https://github.com/tpetric7/language_models_workshop/blob/main/Shiny_app_how_to_prepare.pdf).
